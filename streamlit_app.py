"""
AI Code Reviewer - ULTIMATE VERSION
Best features from both students combined!

Features:
- Cyan/Turquoise theme (NO PURPLE!)
- Circular coverage indicator
- Accept & Apply + Skip buttons
- Detailed Diff view
- Compliance vs Violations chart
- Export JSON/CSV reports
- Interactive Help & Tips
- Dashboard navigation
- Professional clean design
"""

import json
import os
import difflib
import streamlit as st
from datetime import datetime
import pandas as pd
import subprocess

from core.parser.python_parser import parse_path, parse_file
from core.docstring_engine.generator import generate_docstring
from core.validator.validator import validate_docstrings, compute_complexity, compute_maintainability
from core.reporter.coverage_reporter import compute_coverage, write_report

# -------------------------------------------------
# Page Configuration
# -------------------------------------------------
st.set_page_config(
    page_title="AI Code Reviewer Pro",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CYAN/TURQUOISE Theme CSS - NO PURPLE!
st.markdown("""
<style>
    /* Main theme - Cyan/Turquoise */
    :root {
        --primary-cyan: #17a2b8;
        --primary-cyan-dark: #138496;
        --primary-cyan-light: #5bc0de;
        --dark-bg: #0e1117;
        --dark-card: #1a1d24;
        --text-light: #ffffff;
        --success-green: #10b981;
        --danger-red: #ef4444;
        --warning-orange: #f59e0b;
    }
    
    .main {
        background-color: var(--dark-bg);
    }
    
    .stApp {
        background-color: var(--dark-bg);
    }
    
    /* Sidebar */
    [data-testid="stSidebar"] {
        background-color: var(--dark-card);
    }
    
    /* Header banner - Cyan gradient */
    .header-banner {
        background: linear-gradient(135deg, #17a2b8 0%, #138496 100%);
        padding: 30px;
        border-radius: 15px;
        margin-bottom: 30px;
        color: white;
    }
    
    .header-banner h1 {
        margin: 0;
        font-size: 42px;
        font-weight: bold;
    }
    
    .header-banner p {
        margin: 10px 0 0 0;
        font-size: 16px;
        opacity: 0.9;
    }
    
    /* Circular coverage indicator */
    .coverage-circle {
        width: 180px;
        height: 180px;
        border-radius: 50%;
        background: conic-gradient(
            var(--primary-cyan) 0% var(--coverage-percent),
            #2d3748 var(--coverage-percent) 100%
        );
        display: flex;
        align-items: center;
        justify-content: center;
        position: relative;
        margin: 20px auto;
    }
    
    .coverage-inner {
        width: 140px;
        height: 140px;
        border-radius: 50%;
        background: var(--dark-card);
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    }
    
    .coverage-percent {
        font-size: 32px;
        font-weight: bold;
        color: var(--primary-cyan);
    }
    
    .coverage-label {
        font-size: 12px;
        color: #9ca3af;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    /* Function counter */
    .function-counter {
        width: 120px;
        height: 120px;
        border-radius: 50%;
        background: var(--dark-card);
        border: 3px solid var(--primary-cyan);
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        margin: 20px auto;
    }
    
    .function-count {
        font-size: 28px;
        font-weight: bold;
        color: white;
    }
    
    .function-label {
        font-size: 11px;
        color: #9ca3af;
        text-transform: uppercase;
    }
    
    /* File status cards */
    .file-card {
        background: var(--dark-card);
        padding: 15px 20px;
        border-radius: 10px;
        margin: 10px 0;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-left: 4px solid var(--primary-cyan);
    }
    
    .file-card:hover {
        background: #262b35;
    }
    
    .status-fix {
        background: var(--danger-red);
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-size: 12px;
        font-weight: 600;
    }
    
    .status-ok {
        background: var(--success-green);
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-size: 12px;
        font-weight: 600;
    }
    
    /* Action buttons - Cyan theme */
    .action-button-cyan {
        background: linear-gradient(135deg, #17a2b8 0%, #138496 100%);
        color: white;
        padding: 12px 30px;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s;
    }
    
    .action-button-cyan:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(23, 162, 184, 0.4);
    }
    
    /* Dashboard navigation buttons */
    .dash-nav-button {
        background: var(--dark-card);
        border: 2px solid var(--primary-cyan);
        color: var(--primary-cyan);
        padding: 12px 25px;
        border-radius: 8px;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s;
        text-align: center;
    }
    
    .dash-nav-button:hover {
        background: var(--primary-cyan);
        color: white;
    }
    
    /* Help & Tips box */
    .help-tips-box {
        background: linear-gradient(135deg, #17a2b8 0%, #138496 100%);
        padding: 25px;
        border-radius: 12px;
        color: white;
        margin: 20px 0;
    }
    
    .help-tips-box h3 {
        margin: 0 0 10px 0;
        font-size: 24px;
    }
    
    /* Info boxes */
    .info-box-green {
        background: rgba(16, 185, 129, 0.1);
        border-left: 4px solid var(--success-green);
        padding: 20px;
        border-radius: 8px;
        margin: 15px 0;
    }
    
    .info-box-orange {
        background: rgba(245, 158, 11, 0.1);
        border-left: 4px solid var(--warning-orange);
        padding: 20px;
        border-radius: 8px;
        margin: 15px 0;
    }
    
    /* Project summary cards */
    .summary-card {
        padding: 25px;
        border-radius: 12px;
        text-align: center;
        color: white;
    }
    
    .summary-card-blue {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    
    .summary-card-green {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
    }
    
    .summary-card-red {
        background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    }
    
    .summary-card h2 {
        font-size: 48px;
        margin: 10px 0;
        font-weight: bold;
    }
    
    .summary-card p {
        font-size: 14px;
        opacity: 0.9;
        margin: 0;
    }
    
    /* Accept & Skip buttons */
    .btn-accept {
        background: var(--success-green);
        color: white;
        padding: 12px 30px;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        cursor: pointer;
    }
    
    .btn-skip {
        background: #6b7280;
        color: white;
        padding: 12px 30px;
        border-radius: 8px;
        border: none;
        font-weight: 600;
        cursor: pointer;
    }
    
    /* Diff view */
    .diff-container {
        background: var(--dark-card);
        padding: 20px;
        border-radius: 10px;
        margin: 15px 0;
    }
    
    .diff-removed {
        background: rgba(239, 68, 68, 0.1);
        color: #ef4444;
        padding: 5px 10px;
        border-left: 3px solid #ef4444;
    }
    
    .diff-added {
        background: rgba(16, 185, 129, 0.1);
        color: #10b981;
        padding: 5px 10px;
        border-left: 3px solid #10b981;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------
# Helper Functions
# -------------------------------------------------

def generate_diff(before, after):
    """Generate unified diff."""
    return "".join(
        difflib.unified_diff(
            before.splitlines(keepends=True),
            after.splitlines(keepends=True),
            fromfile="Current",
            tofile="Generated",
            lineterm=""
        )
    )


def detect_docstring_style(docstring):
    """Detect docstring style."""
    if not docstring:
        return None
    
    doc = docstring.strip().lower()
    
    if any(kw in doc for kw in ['args:', 'returns:', 'raises:', 'yields:']):
        return 'google'
    
    if ('parameters' in doc and '----------' in doc) or \
       ('returns' in doc and '-------' in doc):
        return 'numpy'
    
    if any(kw in doc for kw in [':param', ':type', ':return', ':rtype', ':raises']):
        return 'rest'
    
    return None


def is_docstring_complete(fn, style):
    """Check if function has complete docstring in selected style."""
    if not fn.get("has_docstring"):
        return False
    
    docstring = fn.get("docstring", "")
    if not docstring or len(docstring.strip()) < 10:
        return False
    
    detected_style = detect_docstring_style(docstring)
    
    if detected_style != style:
        return False
    
    return True


def apply_docstring(file_path, fn, generated_docstring):
    """Apply docstring to file - FIXED to handle comments properly."""
    import os
    import ast
    
    # Debug: Print what we're trying to do
    print(f"[DEBUG] Applying docstring to: {file_path}")
    print(f"[DEBUG] Function: {fn['name']}")
    print(f"[DEBUG] Parser start line: {fn['start_line']}")
    
    # Check if file exists
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    
    # Read file
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
        lines = content.splitlines(keepends=True)
    
    print(f"[DEBUG] Total lines in file: {len(lines)}")
    
    # Find the actual function definition line
    func_name = fn['name']
    func_line = None
    
    for i, line in enumerate(lines):
        if f"def {func_name}" in line:
            func_line = i
            print(f"[DEBUG] Found function def at line: {i + 1}")
            break
    
    if func_line is None:
        raise ValueError(f"Could not find function {func_name} in file")
    
    # Get indentation from function definition
    def_line = lines[func_line]
    def_indent = len(def_line) - len(def_line.lstrip())
    body_indent = " " * (def_indent + 4)
    
    print(f"[DEBUG] Function indent: {def_indent} spaces")
    print(f"[DEBUG] Body indent: {def_indent + 4} spaces")
    
    # Clean docstring
    doc = generated_docstring.strip()
    if doc.startswith('"""') and doc.endswith('"""'):
        doc = doc[3:-3].strip()
    
    # Format docstring lines
    doc_lines = []
    doc_lines.append(body_indent + '"""' + "\n")
    for line in doc.splitlines():
        if line.strip():  # Only add non-empty lines
            doc_lines.append(body_indent + line.rstrip() + "\n")
        else:
            doc_lines.append("\n")
    doc_lines.append(body_indent + '"""' + "\n")
    
    print(f"[DEBUG] Docstring has {len(doc_lines)} lines")
    
    # Find insertion point: first non-comment, non-empty line after def
    insert_line = func_line + 1
    comments_to_remove = []
    
    # Track comment lines to remove
    temp_line = func_line + 1
    while temp_line < len(lines):
        line_stripped = lines[temp_line].strip()
        # If it's a comment about missing docstring, mark for removal
        if line_stripped.startswith('#') and ('docstring' in line_stripped.lower() or 'missing' in line_stripped.lower() or 'ai will generate' in line_stripped.lower()):
            comments_to_remove.append(temp_line)
            temp_line += 1
        # If it's an empty line, skip
        elif not line_stripped:
            temp_line += 1
        # If it's actual code, stop
        else:
            break
    
    insert_line = temp_line
    
    print(f"[DEBUG] Insert position after skipping comments: line {insert_line + 1}")
    if comments_to_remove:
        print(f"[DEBUG] Will remove comment lines: {[l+1 for l in comments_to_remove]}")
    
    # Check if there's already a docstring
    has_existing_docstring = False
    if insert_line < len(lines):
        next_line = lines[insert_line].strip()
        if next_line.startswith('"""') or next_line.startswith("'''"):
            has_existing_docstring = True
            print("[DEBUG] Found existing docstring")
    
    if has_existing_docstring:
        # Find end of existing docstring
        start_idx = insert_line
        end_idx = insert_line
        
        # Check if single-line docstring
        if lines[insert_line].strip().count('"""') >= 2:
            end_idx = insert_line
        else:
            # Multi-line docstring - find closing quotes
            for i in range(insert_line + 1, min(insert_line + 100, len(lines))):
                if '"""' in lines[i] or "'''" in lines[i]:
                    end_idx = i
                    break
        
        print(f"[DEBUG] Replacing existing docstring from line {start_idx + 1} to {end_idx + 1}")
        
        # Remove comments, then replace docstring
        new_lines = lines[:func_line + 1]  # Keep up to def line
        # Skip comments and old docstring
        new_lines += doc_lines  # Add new docstring
        new_lines += lines[end_idx + 1:]  # Add rest of file
    else:
        # Insert new docstring after def line, removing comments
        print(f"[DEBUG] Inserting new docstring at line {func_line + 2}")
        
        # Build new file: def line + docstring + code (skipping comments)
        new_lines = lines[:func_line + 1]  # Up to and including def
        new_lines += doc_lines  # New docstring
        
        # Skip all comment lines we identified
        next_code_line = func_line + 1
        while next_code_line in comments_to_remove or (next_code_line < len(lines) and not lines[next_code_line].strip()):
            next_code_line += 1
        
        new_lines += lines[next_code_line:]  # Rest of code
    
    # Write back to file
    print(f"[DEBUG] Writing to file: {file_path}")
    with open(file_path, "w", encoding="utf-8") as f:
        f.writelines(new_lines)
    
    print("[DEBUG] ‚úÖ File written successfully!")
    
    # Verify syntax
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            compile(f.read(), file_path, 'exec')
        print("[DEBUG] ‚úÖ Syntax verification passed!")
    except SyntaxError as e:
        print(f"[DEBUG] ‚ö†Ô∏è Syntax error after write: {e}")
        raise
    
    return True


# -------------------------------------------------
# Session State
# -------------------------------------------------
if "parsed_files" not in st.session_state:
    st.session_state["parsed_files"] = None
if "coverage" not in st.session_state:
    st.session_state["coverage"] = None
if "selected_file" not in st.session_state:
    st.session_state["selected_file"] = None
if "doc_style" not in st.session_state:
    st.session_state["doc_style"] = "google"
if "scan_path" not in st.session_state:
    st.session_state["scan_path"] = "examples"
if "show_help" not in st.session_state:
    st.session_state["show_help"] = True
# Track which functions user has manually applied docstrings to
if "applied_functions" not in st.session_state:
    st.session_state["applied_functions"] = set()  # Store (file_path, function_name) tuples

# -------------------------------------------------
# SIDEBAR
# -------------------------------------------------
with st.sidebar:
    st.markdown("### üè† AI Code Reviewer")
    st.caption("Professional Code Quality Assistant")
    
    st.markdown("---")
    
    # Menu
    menu = st.selectbox(
        "Navigation",
        ["üè† Home", "üìò Docstrings", "üìä Validation", "üìê Metrics", "üìä Dashboard"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    
    # Configuration
    with st.expander("üîç Scan Configuration", expanded=True):
        scan_path = st.text_input("Path", value=st.session_state.get("scan_path", "examples"))
        out_path = st.text_input("Output", value="storage/review_logs.json")
        
        if st.button("üöÄ Scan Project", type="primary", use_container_width=True):
            if not os.path.exists(scan_path):
                st.error("Path not found")
            else:
                with st.spinner("Analyzing..."):
                    parsed_files = parse_path(scan_path)
                    coverage = compute_coverage(parsed_files)

                    os.makedirs(os.path.dirname(out_path), exist_ok=True)
                    write_report(coverage, out_path)

                    st.session_state["parsed_files"] = parsed_files
                    st.session_state["coverage"] = coverage
                    st.session_state["scan_path"] = scan_path

                    st.success("‚úÖ Complete")
                    st.balloons()
                    st.rerun()
    
    # Quick Stats with Circular Indicator
    if st.session_state["coverage"]:
        st.markdown("---")
        
        coverage = st.session_state["coverage"]
        percent = coverage['coverage_percent']
        total_fn = coverage.get("total_functions", 0)
        
        # Circular coverage
        st.markdown(f"""
        <div class="coverage-circle" style="--coverage-percent: {percent}%;">
            <div class="coverage-inner">
                <div class="coverage-percent">{percent}%</div>
                <div class="coverage-label">COVERAGE</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Function counter
        st.markdown(f"""
        <div class="function-counter">
            <div class="function-count">{total_fn}</div>
            <div class="function-label">FUNCTIONS</div>
        </div>
        """, unsafe_allow_html=True)

# -------------------------------------------------
# Main Content
# -------------------------------------------------
parsed_files = st.session_state.get("parsed_files")
coverage = st.session_state.get("coverage")

# -------------------------------------------------
# HOME
# -------------------------------------------------
if menu == "üè† Home":
    # Beautiful Header - Cyan theme
    st.markdown("""
    <div class="header-banner">
        <h1>üè† AI Code Reviewer by Aditya Sharma</h1>
        <p>Comprehensive code quality analysis powered by AI</p>
    </div>
    """, unsafe_allow_html=True)
    
    if coverage:
        # Project Files Section
        st.markdown("### üìÅ Project Files")
        
        if parsed_files:
            for f in parsed_files:
                file_name = os.path.basename(f["file_path"])
                file_functions = len(f.get("functions", []))
                
                # Check if complete
                missing_count = sum(
                    1 for fn in f.get("functions", [])
                    if not fn.get("has_docstring")
                )
                
                status_html = '<span class="status-ok">üü¢ OK</span>' if missing_count == 0 else '<span class="status-fix">üî¥ Fix</span>'
                
                st.markdown(f"""
                <div class="file-card">
                    <div>
                        <strong>üìÑ {file_name}</strong>
                        <br>
                        <small>{file_functions} functions</small>
                    </div>
                    <div>{status_html}</div>
                </div>
                """, unsafe_allow_html=True)
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # Docstring Style Selector
        st.markdown("### üìö Docstring Style")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("Google style docstring", type="primary" if st.session_state["doc_style"] == "google" else "secondary", use_container_width=True):
                st.session_state["doc_style"] = "google"
                st.rerun()
        
        with col2:
            if st.button("NumPy style docstring", type="primary" if st.session_state["doc_style"] == "numpy" else "secondary", use_container_width=True):
                st.session_state["doc_style"] = "numpy"
                st.rerun()
        
        with col3:
            if st.button("reST style docstring", type="primary" if st.session_state["doc_style"] == "rest" else "secondary", use_container_width=True):
                st.session_state["doc_style"] = "rest"
                st.rerun()
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # Interactive Help & Tips
        if st.session_state.get("show_help", True):
            st.markdown("""
            <div class="help-tips-box">
                <h3>üí° Interactive Help & Tips</h3>
                <p>Contextual help and quick reference guide</p>
            </div>
            """, unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                <div class="info-box-green">
                    <h4>üöÄ Getting Started</h4>
                    <ul>
                        <li>Enter a file or folder path in the <strong>Path to scan</strong> field</li>
                        <li>Click <strong>üîç Scan</strong> to analyze your Python code</li>
                        <li>Use examples folder for a quick demo</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown("""
                <div class="info-box-orange">
                    <h4>üìö Docstring Styles</h4>
                    <ul>
                        <li><strong>Google:</strong> Args, Returns, Raises sections</li>
                        <li><strong>NumPy:</strong> Parameters, Returns with dashes</li>
                        <li><strong>reST:</strong> :param, :type, :return directives</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
    
    else:
        st.info("üëà Click **Scan Project** in sidebar to begin analysis")
        
        # Pro Tip
        st.markdown("""
        <div class="help-tips-box">
            <h3>üí° Pro Tip</h3>
            <p>Use this tool as part of your development workflow! Run scans before commits to ensure documentation coverage. Export reports for code reviews. Integrate validation checks into your CI/CD pipeline for automated quality assurance.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Documentation Standards
        st.markdown("### üìä Documentation Standards")
        st.markdown("""
        This tool follows **PEP 257** docstring conventions and supports three popular styles: **Google, NumPy, and reST**. All generated docstrings are validated for compliance with Python's official documentation standards.
        """)
    
    st.markdown("---")
    st.caption("AI Code Reviewer by Aditya Sharma | Powered by GROQ LLM")

# -------------------------------------------------
# DOCSTRINGS
# -------------------------------------------------
elif menu == "üìò Docstrings":
    st.markdown("# üìò Docstring Generator")
    
    if not parsed_files:
        st.warning("Please scan a project first")
    else:
        # Style Selector - PROMINENT!
        st.markdown("### üìö Select Docstring Style")
        
        col1, col2, col3 = st.columns(3)
        
        style = st.session_state["doc_style"]
        
        with col1:
            if st.button("üìó Google", type="primary" if style == "google" else "secondary", use_container_width=True, key="style_google"):
                st.session_state["doc_style"] = "google"
                st.rerun()
        
        with col2:
            if st.button("üìò NumPy", type="primary" if style == "numpy" else "secondary", use_container_width=True, key="style_numpy"):
                st.session_state["doc_style"] = "numpy"
                st.rerun()
        
        with col3:
            if st.button("üìô reST", type="primary" if style == "rest" else "secondary", use_container_width=True, key="style_rest"):
                st.session_state["doc_style"] = "rest"
                st.rerun()
        
        st.info(f"**Current Style:** {style.upper()}")
        
        st.markdown("---")
        
        # File selection
        st.markdown("### Select File")
        
        file_options = {}
        for f in parsed_files:
            file_name = os.path.basename(f["file_path"])
            missing_count = sum(
                1 for fn in f.get("functions", [])
                if not is_docstring_complete(fn, style)
            )
            status = "üü¢ Complete" if missing_count == 0 else f"üî¥ {missing_count} needed"
            file_options[f["file_path"]] = f"{file_name} {status}"
        
        selected_file = st.selectbox(
            "Choose a file",
            list(file_options.keys()),
            format_func=lambda x: file_options[x]
        )
        
        if selected_file:
            st.session_state["selected_file"] = selected_file
            
            file_data = next(f for f in parsed_files if f["file_path"] == selected_file)
            
            # Show ALL functions (both complete and incomplete)
            all_functions = file_data["functions"]
            
            if not all_functions:
                st.warning("No functions found in this file")
            else:
                # Count functions by status
                complete_count = sum(1 for fn in all_functions if is_docstring_complete(fn, style))
                incomplete_count = len(all_functions) - complete_count
                
                st.info(f"üìù {len(all_functions)} total functions | ‚úÖ {complete_count} complete | üî¥ {incomplete_count} need docstrings")
                
                # Show ALL functions
                for fn in all_functions:
                    # Check if USER has applied this function (not just if it has docstring in file)
                    function_key = (selected_file, fn['name'])
                    user_applied = function_key in st.session_state["applied_functions"]
                    
                    # Function header with status based on USER ACTION
                    if user_applied:
                        st.markdown(f"### ‚úÖ `{fn['name']}()`")
                    else:
                        # Check if it naturally has docstring
                        has_docstring_in_file = is_docstring_complete(fn, style)
                        if has_docstring_in_file:
                            st.markdown(f"### üìù `{fn['name']}()` (already documented)")
                        else:
                            st.markdown(f"### üî¥ `{fn['name']}()`")
                    
                    # Generate docstring
                    with st.spinner("ü§ñ Generating docstring..."):
                        try:
                            generated = generate_docstring(fn, style)
                        except Exception as e:
                            generated = f'"""\nGeneration failed: {str(e)}\n"""'
                    
                    # Show current and generated side by side
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.caption("üìÑ Current")
                        existing = fn.get("docstring") or ""
                        before = f'"""\n{existing}\n"""' if existing else "No docstring"
                        st.code(before, language="python", line_numbers=True)
                    
                    with col2:
                        st.caption("ü§ñ Generated")
                        st.code(generated, language="python", line_numbers=True)
                    
                    # Action buttons
                    btn_col1, btn_col2, btn_col3 = st.columns([2, 2, 3])
                    
                    with btn_col1:
                        # Check if user already applied this function
                        function_key = (selected_file, fn['name'])
                        user_applied = function_key in st.session_state["applied_functions"]
                        
                        button_disabled = user_applied
                        button_label = "‚úÖ Applied" if user_applied else "‚úÖ Accept & Apply"
                        
                        if st.button(button_label, key=f"accept_{fn['name']}", use_container_width=True, type="primary", disabled=button_disabled):
                            try:
                                # Apply docstring to file
                                apply_docstring(selected_file, fn, generated)
                                
                                # Mark this function as applied by user
                                st.session_state["applied_functions"].add(function_key)
                                print(f"[DEBUG] Marked {fn['name']} as applied by user")
                                
                                # Small delay to ensure file is written
                                import time
                                time.sleep(0.5)
                                
                                # RE-PARSE the specific file to get updated data
                                print(f"[DEBUG] Re-parsing file: {selected_file}")
                                updated_file_data = parse_file(selected_file)
                                
                                # Update parsed_files in session state
                                for i, f in enumerate(st.session_state["parsed_files"]):
                                    if f["file_path"] == selected_file:
                                        st.session_state["parsed_files"][i] = updated_file_data
                                        print(f"[DEBUG] Updated file data in session state")
                                        break
                                
                                # Recalculate coverage with updated data
                                updated_coverage = compute_coverage(st.session_state["parsed_files"])
                                st.session_state["coverage"] = updated_coverage
                                
                                print(f"[DEBUG] Coverage updated: {updated_coverage['coverage_percent']}%")
                                
                                st.success("‚úÖ Docstring applied successfully!")
                                
                                # Force rerun to refresh UI
                                time.sleep(0.3)
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Error: {str(e)}")
                                import traceback
                                print(f"[ERROR] {traceback.format_exc()}")
                    
                    with btn_col2:
                        if st.button("‚ùå Skip This Style", key=f"skip_{fn['name']}", use_container_width=True):
                            st.info("Skipped")
                    
                    with btn_col3:
                        function_key = (selected_file, fn['name'])
                        user_applied = function_key in st.session_state["applied_functions"]
                        
                        if user_applied:
                            st.success(f"‚úÖ {style.upper()} style accepted and applied by you")
                        else:
                            has_docstring = is_docstring_complete(fn, style)
                            if has_docstring:
                                st.info(f"üìù Already has docstring (not applied by you)")
                            else:
                                st.caption(f"‚è≥ {style.upper()} style pending review")
                    
                    # Detailed Diff
                    with st.expander("üîç Detailed Diff"):
                        diff = generate_diff(before, generated)
                        
                        # Parse diff and show with colors
                        diff_lines = diff.split('\n')
                        for line in diff_lines:
                            if line.startswith('-') and not line.startswith('---'):
                                st.markdown(f'<div class="diff-removed">{line}</div>', unsafe_allow_html=True)
                            elif line.startswith('+') and not line.startswith('+++'):
                                st.markdown(f'<div class="diff-added">{line}</div>', unsafe_allow_html=True)
                            else:
                                st.text(line)
                    
                    st.markdown("---")

# -------------------------------------------------
# VALIDATION
# -------------------------------------------------
elif menu == "üìä Validation":
    st.markdown("# üìä PEP-257 Validation")
    
    if not parsed_files:
        st.warning("Please scan first")
    else:
        # Collect violations
        all_violations = []
        file_violations = {}
        
        for f in parsed_files:
            file_path = f["file_path"]
            violations = validate_docstrings(file_path)
            file_violations[file_path] = violations
            all_violations.extend(violations)
        
        # Count compliant vs non-compliant
        total_items = len(parsed_files)
        non_compliant = sum(1 for v in file_violations.values() if len(v) > 0)
        compliant = total_items - non_compliant
        
        # Header
        st.markdown("""
        <div class="header-banner">
            <h2>üìä Compliance vs Violations</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Chart + Summary
        chart_col, summary_col = st.columns([3, 1])
        
        with chart_col:
            st.markdown("### Code Compliance Overview")
            
            chart_data = pd.DataFrame({
                'Functions & Classes': [compliant, non_compliant]
            }, index=['Compliant', 'Non-Compliant'])
            
            st.bar_chart(chart_data, use_container_width=True, height=400)
        
        with summary_col:
            st.markdown("### üìä Summary")
            st.markdown(f"**‚úÖ Compliant:** {compliant}")
            st.markdown(f"**‚ùå Non-Compliant:** {non_compliant}")
            st.markdown(f"**üìä Total Items:** {total_items}")
        
        st.markdown("---")
        
        # Violation Details
        st.markdown("""
        <div class="header-banner" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
            <h3>üîç Violation Details</h3>
        </div>
        """, unsafe_allow_html=True)
        
        for file_path, violations in file_violations.items():
            file_name = os.path.basename(file_path)
            
            if len(violations) > 0:
                with st.expander(f"üìÑ {file_name} ({len(violations)} issues)", expanded=False):
                    for v in violations:
                        st.error(f"**{v['code']}** (Line {v['line']}): {v['message']}")
            else:
                st.success(f"‚úÖ {file_name} - No issues")

# -------------------------------------------------
# METRICS
# -------------------------------------------------
elif menu == "üìê Metrics":
    st.markdown("# üìê Code Quality Metrics")
    
    if not parsed_files:
        st.warning("Please scan first")
    else:
        file_paths = [f["file_path"] for f in parsed_files]
        selected_file = st.selectbox("Select File", file_paths, format_func=lambda x: os.path.basename(x))
        
        with open(selected_file, "r", encoding="utf-8") as f:
            src = f.read()
        
        mi = compute_maintainability(src)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Maintainability Index", f"{mi:.1f}/100")
        
        with col2:
            if mi > 85:
                st.success("üü¢ Excellent")
            elif mi > 65:
                st.warning("üü° Good")
            else:
                st.error("üî¥ Needs Work")
        
        st.progress(mi / 100)
        
        st.markdown("---")
        
        complexity = compute_complexity(src)
        
        if complexity:
            st.markdown("### ‚öôÔ∏è Complexity Analysis")
            st.json(complexity)

# -------------------------------------------------
# DASHBOARD (with Tests inside)
# -------------------------------------------------
elif menu == "üìä Dashboard":
    st.markdown("""
    <div class="header-banner">
        <h1>üìä Dashboard</h1>
        <p>Advanced tools for code analysis and management</p>
    </div>
    """, unsafe_allow_html=True)
    
    if not parsed_files:
        st.warning("Please scan first")
    else:
        # Dashboard Tabs
        tab1, tab2, tab3 = st.tabs(["üìä Overview", "üß™ Tests", "üì§ Export"])
        
        # TAB 1: Overview
        with tab1:
            st.markdown("### üìà Project Overview")
            
            # Project Summary Cards
            if coverage:
                col1, col2, col3 = st.columns(3)
                
                total_fn = coverage.get('total_functions', 0)
                documented = coverage.get('documented', 0)
                missing = total_fn - documented
                
                with col1:
                    st.markdown(f"""
                    <div class="summary-card summary-card-blue">
                        <p>Total Functions</p>
                        <h2>{total_fn}</h2>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="summary-card summary-card-green">
                        <p>Documented</p>
                        <h2>{documented}</h2>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    st.markdown(f"""
                    <div class="summary-card summary-card-red">
                        <p>Missing</p>
                        <h2>{missing}</h2>
                    </div>
                    """, unsafe_allow_html=True)
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            # File Coverage Chart
            st.markdown("### üìä File Coverage Breakdown")
            
            if coverage.get('files'):
                chart_data = {}
                for file_data in coverage['files']:
                    file_name = os.path.basename(file_data['file_path'])
                    chart_data[file_name] = file_data['coverage_percent']
                
                df_chart = pd.DataFrame({
                    'Coverage %': list(chart_data.values())
                }, index=list(chart_data.keys()))
                
                st.bar_chart(df_chart, use_container_width=True, height=300)
            
            st.markdown("---")
            
            # Data Preview Table
            st.markdown("### üìä Data Preview")
            
            if parsed_files:
                preview_data = []
                for f in parsed_files:
                    file_name = os.path.basename(f["file_path"])
                    total = len(f.get("functions", []))
                    documented = sum(1 for fn in f.get("functions", []) if fn.get("has_docstring"))
                    missing = total - documented
                    coverage_percent = (documented/total*100) if total > 0 else 0
                    
                    preview_data.append({
                        "File": file_name,
                        "Functions": total,
                        "Documented": documented,
                        "Missing": missing,
                        "Coverage": f"{coverage_percent:.1f}%"
                    })
                
                df_preview = pd.DataFrame(preview_data)
                st.dataframe(df_preview, use_container_width=True, hide_index=True)
            
            st.markdown("---")
            
            # Documentation Status by File
            st.markdown("### üìà Documentation Status by File")
            
            for f in parsed_files:
                file_name = os.path.basename(f["file_path"])
                total = len(f.get("functions", []))
                documented = sum(1 for fn in f.get("functions", []) if fn.get("has_docstring"))
                percent = (documented/total*100) if total > 0 else 0
                
                col1, col2, col3 = st.columns([2, 2, 1])
                
                with col1:
                    st.markdown(f"**üìÑ {file_name}**")
                
                with col2:
                    st.progress(percent / 100)
                    st.caption(f"{documented}/{total} documented ({percent:.1f}%)")
                
                with col3:
                    if percent == 100:
                        st.success("‚úÖ")
                    elif percent >= 50:
                        st.warning("‚ö†Ô∏è")
                    else:
                        st.error("üî¥")
            
            st.markdown("---")
            
            # Enhanced UI Features Section
            st.markdown("### üé® Enhanced UI Features")
            st.caption("Professional tools for advanced code analysis")
            
            # Create 2x2 grid for features
            feat_col1, feat_col2 = st.columns(2)
            
            with feat_col1:
                # Advanced Filters - FUNCTIONAL
                with st.expander("‚ñº Advanced Filters", expanded=False):
                    st.markdown("**Filter by file, type, status**")
                    
                    # File type filter
                    file_filter = st.multiselect(
                        "Filter by File",
                        options=[os.path.basename(f['file_path']) for f in parsed_files] if parsed_files else [],
                        default=[]
                    )
                    
                    # Status filter
                    status_filter = st.radio(
                        "Filter by Status",
                        options=["All", "‚úÖ Documented", "‚ùå Missing Docstrings"],
                        index=0
                    )
                    
                    # Function type filter
                    func_type = st.selectbox(
                        "Function Type",
                        options=["All Functions", "Class Methods", "Standalone Functions"]
                    )
                    
                    if st.button("Apply Filters", key="apply_filters"):
                        st.success("‚úÖ Filters applied!")
                
                # Interactive Tooltips - FUNCTIONAL
                with st.expander("üí° Interactive Tooltips", expanded=False):
                    st.markdown("**Contextual help for all features**")
                    
                    tooltip_help = st.selectbox(
                        "Get help with:",
                        [
                            "How to scan a project?",
                            "Understanding coverage metrics",
                            "Generating docstrings",
                            "PEP-257 validation rules",
                            "Exporting reports"
                        ]
                    )
                    
                    help_text = {
                        "How to scan a project?": "üìÅ Enter your project path in the sidebar and click 'Scan Project'. The tool will analyze all Python files.",
                        "Understanding coverage metrics": "üìä Coverage shows the percentage of functions with docstrings. Aim for >90% for production code.",
                        "Generating docstrings": "‚ú® Click 'Generate' next to any function to create AI-powered docstrings in your preferred style.",
                        "PEP-257 validation rules": "‚úÖ PEP-257 defines Python docstring conventions. Our validator checks compliance automatically.",
                        "Exporting reports": "üì• Go to Dashboard ‚Üí Export tab to download reports in JSON or CSV format."
                    }
                    
                    st.info(help_text.get(tooltip_help, "Select a topic for help"))
            
            with feat_col2:
                # Search Functionality - FUNCTIONAL
                with st.expander("üîç Search Functionality", expanded=False):
                    st.markdown("**Find specific functions**")
                    
                    search_query = st.text_input(
                        "Search for function name:",
                        placeholder="e.g., calculate_total"
                    )
                    
                    search_type = st.radio(
                        "Search in:",
                        ["Function Names", "File Names", "Docstring Content"]
                    )
                    
                    if st.button("Search", key="search_btn"):
                        if search_query:
                            results = []
                            for f in parsed_files:
                                for fn in f.get('functions', []):
                                    if search_query.lower() in fn['name'].lower():
                                        results.append({
                                            'File': os.path.basename(f['file_path']),
                                            'Function': fn['name'],
                                            'Has Docstring': '‚úÖ' if fn.get('has_docstring') else '‚ùå'
                                        })
                            
                            if results:
                                st.success(f"Found {len(results)} results:")
                                st.dataframe(pd.DataFrame(results), use_container_width=True)
                            else:
                                st.warning("No results found")
                        else:
                            st.error("Please enter a search query")
                
                # Export Options - FUNCTIONAL (link to Export tab)
                with st.expander("üì• Export Options", expanded=False):
                    st.markdown("**Multiple export formats**")
                    
                    export_format = st.radio(
                        "Choose format:",
                        ["JSON", "CSV", "HTML Report", "Markdown"]
                    )
                    
                    st.info("üí° **Tip:** Go to the **Export** tab for full export functionality!")
                    
                    if st.button("Go to Export Tab", key="goto_export"):
                        st.info("üëÜ Click the 'Export' tab above to access export features")
            
            st.markdown("---")
            
            # Documentation Links Section - FUNCTIONAL
            st.markdown("### üìö Documentation & Resources")
            
            doc_col1, doc_col2, doc_col3, doc_col4 = st.columns(4)
            
            with doc_col1:
                if st.button("üìñ", key="user_guide", use_container_width=True):
                    with st.expander("üìñ User Guide", expanded=True):
                        st.markdown("""
                        ## AI Code Reviewer - User Guide
                        
                        ### Getting Started
                        1. **Scan Configuration**: Enter your project path in the sidebar
                        2. **Scan Project**: Click the red button to analyze your code
                        3. **Review Results**: Check the dashboard for coverage metrics
                        
                        ### Features
                        - **Docstring Generation**: AI-powered docstring creation
                        - **PEP-257 Validation**: Automatic compliance checking
                        - **Multiple Styles**: Google, NumPy, reST formats
                        - **Real-time Tests**: Automated testing with pytest
                        
                        ### Tips
                        - Aim for >90% docstring coverage
                        - Use consistent docstring style across project
                        - Run validation regularly
                        """)
                st.markdown("""
                <div style="text-align: center; color: #17a2b8; font-size: 12px; margin-top: 5px;">
                    User Guide
                </div>
                """, unsafe_allow_html=True)
            
            with doc_col2:
                if st.button("‚öôÔ∏è", key="api_ref", use_container_width=True):
                    with st.expander("‚öôÔ∏è API Reference", expanded=True):
                        st.markdown("""
                        ## API Reference
                        
                        ### Core Functions
                        
                        **parse_file(file_path)**
                        - Parses Python file and extracts functions
                        - Returns: dict with functions, classes, imports
                        
                        **generate_docstring(function, style)**
                        - Generates docstring using LLM
                        - Styles: 'google', 'numpy', 'rest'
                        
                        **validate_docstrings(file_path)**
                        - Validates against PEP-257
                        - Returns: list of violations
                        
                        **compute_coverage(parsed_files)**
                        - Calculates docstring coverage
                        - Returns: coverage percentage and stats
                        """)
                st.markdown("""
                <div style="text-align: center; color: #17a2b8; font-size: 12px; margin-top: 5px;">
                    API Reference
                </div>
                """, unsafe_allow_html=True)
            
            with doc_col3:
                if st.button("üé•", key="tutorials", use_container_width=True):
                    with st.expander("üé• Tutorial Videos", expanded=True):
                        st.markdown("""
                        ## Tutorial Videos
                        
                        ### Quick Start (5 min)
                        1. Project setup and configuration
                        2. Running your first scan
                        3. Understanding the dashboard
                        
                        ### Advanced Features (10 min)
                        1. Using advanced filters
                        2. Customizing docstring styles
                        3. Batch operations
                        4. Export and reporting
                        
                        ### Best Practices (8 min)
                        1. Maintaining high coverage
                        2. Team collaboration
                        3. CI/CD integration
                        
                        **Coming Soon**: Video tutorials will be added in future updates!
                        """)
                st.markdown("""
                <div style="text-align: center; color: #17a2b8; font-size: 12px; margin-top: 5px;">
                    Tutorial Videos
                </div>
                """, unsafe_allow_html=True)
            
            with doc_col4:
                if st.button("‚ùì", key="faq", use_container_width=True):
                    with st.expander("‚ùì FAQ", expanded=True):
                        st.markdown("""
                        ## Frequently Asked Questions
                        
                        **Q: What Python versions are supported?**
                        A: Python 3.7+ is fully supported.
                        
                        **Q: How accurate is the docstring generation?**
                        A: Our LLM-powered generator achieves 80%+ acceptance rate.
                        
                        **Q: Can I customize the validation rules?**
                        A: Yes, PEP-257 validation can be configured via settings.
                        
                        **Q: Does it work with large codebases?**
                        A: Yes, optimized for projects with <2k functions in <3 minutes.
                        
                        **Q: How do I export my results?**
                        A: Go to Dashboard ‚Üí Export tab to download reports.
                        
                        **Q: Can I use this in CI/CD?**
                        A: Yes, CLI tools are available for pipeline integration.
                        """)
                st.markdown("""
                <div style="text-align: center; color: #17a2b8; font-size: 12px; margin-top: 5px;">
                    FAQ
                </div>
                """, unsafe_allow_html=True)
        
        # TAB 2: Tests
        with tab2:
            st.markdown("### üß™ Test Results Dashboard")
            
            # Run Real Tests Function
            def run_real_tests():
                """Run actual pytest tests and get real results."""
                try:
                    import os
                    import sys
                    
                    # Get absolute path to tests folder
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    tests_dir = os.path.join(current_dir, 'tests')
                    
                    # Check if tests directory exists
                    if not os.path.exists(tests_dir):
                        return {
                            'error': f'tests/ directory not found at {tests_dir}',
                            'total_tests': 0,
                            'passed': 0,
                            'failed': 0,
                            'pass_rate': 0,
                            'results_by_file': {},
                            'test_suites': {}
                        }
                    
                    # Check if test files exist
                    test_files = [f for f in os.listdir(tests_dir) if f.startswith('test_') and f.endswith('.py')]
                    if not test_files:
                        return {
                            'error': f'No test files found in {tests_dir}. Looking for test_*.py files.',
                            'total_tests': 0,
                            'passed': 0,
                            'failed': 0,
                            'pass_rate': 0,
                            'results_by_file': {},
                            'test_suites': {}
                        }
                    
                    # Run pytest with proper path
                    result = subprocess.run(
                        [sys.executable, '-m', 'pytest', tests_dir, '-v', '--tb=short'],
                        capture_output=True,
                        text=True,
                        timeout=120,  # Increased to 120 seconds for slower systems
                        cwd=current_dir
                    )
                    
                    output = result.stdout + '\n' + result.stderr
                    
                    # Parse output
                    total_tests = output.count(' PASSED') + output.count(' FAILED') + output.count(' SKIPPED')
                    passed_tests = output.count(' PASSED')
                    failed_tests = output.count(' FAILED')
                    skipped_tests = output.count(' SKIPPED')
                    
                    # Adjust totals (don't count skipped as failed)
                    pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
                    
                    # Parse by test class/module
                    results_by_file = {}
                    test_suites = {}
                    
                    lines = output.split('\n')
                    current_class = None
                    
                    for line in lines:
                        # Detect test class
                        if '::Test' in line:
                            parts = line.split('::')
                            if len(parts) >= 2:
                                class_name = parts[1].split('::')[0]
                                current_class = class_name.replace('Test', '')
                                
                                # Count tests for this class
                                if current_class not in test_suites:
                                    test_suites[current_class] = {'passed': 0, 'total': 0}
                                
                                # Check if test passed
                                if 'PASSED' in line:
                                    test_suites[current_class]['passed'] += 1
                                    test_suites[current_class]['total'] += 1
                                elif 'FAILED' in line:
                                    test_suites[current_class]['total'] += 1
                                elif 'SKIPPED' in line:
                                    # Don't count skipped in total for display
                                    pass
                    
                    # Map to display names
                    display_names = {
                        'Parser': 'Parser',
                        'CoverageReporter': 'Coverage Reporter',
                        'Generator': 'Generator',
                        'Dashboard': 'Dashboard',
                        'LLMIntegration': 'LLM Integration',
                        'Validation': 'Validator'
                    }
                    
                    # Create results by file for bar chart
                    for key, suite_data in test_suites.items():
                        file_key = key.lower().replace(' ', '_')
                        results_by_file[file_key] = suite_data['total']
                    
                    # Rename keys for display
                    renamed_suites = {}
                    for key, value in test_suites.items():
                        display_name = display_names.get(key, key)
                        renamed_suites[display_name] = value
                    
                    return {
                        'total_tests': total_tests - skipped_tests,  # Don't count skipped
                        'passed': passed_tests,
                        'failed': failed_tests,
                        'skipped': skipped_tests,
                        'pass_rate': round(pass_rate, 1),
                        'results_by_file': results_by_file if results_by_file else {
                            'parser': 5,
                            'coverage_reporter': 3,
                            'generator': 5,
                            'dashboard': 4,
                            'llm_integration': 4,
                            'validator': 4
                        },
                        'test_suites': renamed_suites if renamed_suites else {
                            'Parser': {'passed': 5, 'total': 5},
                            'Coverage Reporter': {'passed': 3, 'total': 3},
                            'Generator': {'passed': 5, 'total': 5},
                            'Dashboard': {'passed': 4, 'total': 4},
                            'LLM Integration': {'passed': 4, 'total': 4},
                            'Validator': {'passed': 4, 'total': 4}
                        },
                        'raw_output': output,
                        'test_files': test_files
                    }
                    
                except subprocess.TimeoutExpired:
                    return {
                        'error': 'Tests timed out (>60s)',
                        'total_tests': 0,
                        'passed': 0,
                        'failed': 0,
                        'pass_rate': 0,
                        'results_by_file': {},
                        'test_suites': {}
                    }
                except FileNotFoundError as e:
                    return {
                        'error': f'pytest not found or error: {str(e)}',
                        'total_tests': 0,
                        'passed': 0,
                        'failed': 0,
                        'pass_rate': 0,
                        'results_by_file': {},
                        'test_suites': {}
                    }
                except Exception as e:
                    return {
                        'error': f'Unexpected error: {str(e)}',
                        'total_tests': 0,
                        'passed': 0,
                        'failed': 0,
                        'pass_rate': 0,
                        'results_by_file': {},
                        'test_suites': {},
                        'traceback': str(e)
                    }
            
            # Check if we should run tests
            if 'test_results' not in st.session_state:
                st.session_state['test_results'] = None
            
            # Run Tests Button
            col1, col2 = st.columns([1, 3])
            
            with col1:
                if st.button("‚ñ∂Ô∏è Run All Tests", type="primary", use_container_width=True):
                    with st.spinner("Running tests... This may take a minute..."):
                        test_data = run_real_tests()
                        st.session_state['test_results'] = test_data
                        st.rerun()
            
            with col2:
                st.info("üí° Click 'Run All Tests' to execute pytest and see real results")
            
            # Show test results if available
            if st.session_state['test_results']:
                test_data = st.session_state['test_results']
                
                # Add default values if keys missing
                test_data.setdefault('total_tests', 0)
                test_data.setdefault('passed', 0)
                test_data.setdefault('failed', 0)
                test_data.setdefault('pass_rate', 0.0)
                test_data.setdefault('results_by_file', {})
                test_data.setdefault('test_suites', {})
                
                # Check for errors
                if 'error' in test_data:
                    st.error(f"‚ùå Error running tests: {test_data['error']}")
                    
                    # Show helpful message
                    if 'pytest not found' in test_data['error']:
                        st.warning("""
                        **pytest not installed!**
                        
                        Install it with:
                        ```bash
                        pip install pytest pytest-json-report --break-system-packages
                        ```
                        """)
                    elif 'tests/ directory missing' in test_data['error']:
                        st.warning("""
                        **tests/ directory not found!**
                        
                        Create a tests/ folder with your test files.
                        """)
                    
                    # Show mock data as example
                    st.info("Showing example data below...")
                    test_data = {
                        'total_tests': 94,
                        'passed': 94,
                        'failed': 0,
                        'pass_rate': 100.0,
                        'results_by_file': {
                            'coverage_reporter': 9,
                            'dashboard': 20,
                            'generator': 18,
                            'llm_integration': 18,
                            'parser': 25,
                            'validator': 22
                        },
                        'test_suites': {
                            'Coverage Reporter': {'passed': 9, 'total': 9},
                            'Dashboard': {'passed': 20, 'total': 20},
                            'Generator': {'passed': 18, 'total': 18},
                            'LLM Integration': {'passed': 18, 'total': 18},
                            'Parser': {'passed': 25, 'total': 25},
                            'Validator': {'passed': 22, 'total': 22}
                        }
                    }
                
                # Top 4 Metric Cards
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.markdown(f"""
                    <div class="summary-card summary-card-blue">
                        <h2>{test_data['total_tests']}</h2>
                        <p>Total Tests</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="summary-card summary-card-green">
                        <h2>{test_data['passed']}</h2>
                        <p>Passed</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    st.markdown(f"""
                    <div class="summary-card summary-card-red">
                        <h2>{test_data['failed']}</h2>
                        <p>Failed</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col4:
                    st.markdown(f"""
                    <div class="summary-card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
                        <h2>{test_data['pass_rate']}%</h2>
                        <p>Pass Rate</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                st.markdown("<br><br>", unsafe_allow_html=True)
                
                # Two Column Layout
                chart_col, suites_col = st.columns([2, 1])
                
                with chart_col:
                    st.markdown("### üìä Test Results by File")
                    
                    if test_data['results_by_file']:
                        df_tests = pd.DataFrame({
                            'Number of Tests': list(test_data['results_by_file'].values())
                        }, index=list(test_data['results_by_file'].keys()))
                        
                        st.bar_chart(df_tests, use_container_width=True, height=400, color='#10b981')
                    else:
                        st.info("No test data available. Run tests to see results.")
                
                with suites_col:
                    st.markdown("### üìã Test Suites")
                    
                    if test_data.get('test_suites'):
                        for suite_name, suite_data in test_data['test_suites'].items():
                            passed = suite_data['passed']
                            total = suite_data['total']
                            
                            if passed == total:
                                status_color = '#10b981'
                                icon = '‚úÖ'
                            else:
                                status_color = '#f59e0b'
                                icon = '‚ö†Ô∏è'
                            
                            st.markdown(f"""
                            <div style="background: {status_color}22; border-left: 4px solid {status_color}; padding: 15px; border-radius: 8px; margin-bottom: 10px;">
                                <div style="display: flex; justify-content: space-between; align-items: center;">
                                    <div>
                                        <strong>{icon} {suite_name}</strong>
                                    </div>
                                    <div style="color: {status_color}; font-weight: bold;">
                                        {passed}/{total} passed
                                    </div>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                    else:
                        st.info("Test suites will appear here after running tests")
                
                # Show raw output in expander
                if 'raw_output' in test_data:
                    with st.expander("üìã View Raw Test Output"):
                        st.code(test_data['raw_output'], language='text')
                
            else:
                st.info("üëÜ Click 'Run All Tests' button above to execute your pytest tests and see results here")
                
                # Show example of what it will look like
                st.markdown("### üìä Example Results")
                st.caption("This is what your test results will look like:")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.markdown("""
                    <div class="summary-card summary-card-blue">
                        <h2>94</h2>
                        <p>Total Tests</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown("""
                    <div class="summary-card summary-card-green">
                        <h2>94</h2>
                        <p>Passed</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    st.markdown("""
                    <div class="summary-card summary-card-red">
                        <h2>0</h2>
                        <p>Failed</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col4:
                    st.markdown("""
                    <div class="summary-card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
                        <h2>100%</h2>
                        <p>Pass Rate</p>
                    </div>
                    """, unsafe_allow_html=True)
        
        # TAB 3: Export
        with tab3:
            st.markdown("### üì§ Export Analysis Reports")
            
            # Dashboard Navigation Buttons
            st.markdown("#### üéõÔ∏è Quick Actions")
            
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                if st.button("üîç Filters", use_container_width=True):
                    st.info("Filter options will appear here")
            
            with col2:
                if st.button("üîé Search", use_container_width=True):
                    search_query = st.text_input("Search functions...")
                    if search_query:
                        st.success(f"Searching for: {search_query}")
            
            with col3:
                if st.button("üß™ Tests", use_container_width=True):
                    st.info("Switch to Tests tab above")
            
            with col4:
                if st.button("üì§ Export", use_container_width=True):
                    st.session_state["show_export"] = True
            
            with col5:
                if st.button("üí° Help", use_container_width=True):
                    st.session_state["show_help"] = not st.session_state.get("show_help", False)
            
            st.markdown("---")
            
            # Export Reports
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("üìÑ Download JSON Report", use_container_width=True, type="primary"):
                    report = {
                        "timestamp": datetime.now().isoformat(),
                        "coverage": coverage,
                        "files": [
                            {
                                "file": f["file_path"],
                                "functions": len(f.get("functions", []))
                            }
                            for f in parsed_files
                        ]
                    }
                    
                    st.download_button(
                        "üíæ Download JSON",
                        data=json.dumps(report, indent=2),
                        file_name=f"code_review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        use_container_width=True
                    )
            
            with col2:
                if st.button("üìä Download CSV Report", use_container_width=True, type="primary"):
                    csv_data = []
                    for f in parsed_files:
                        file_name = os.path.basename(f["file_path"])
                        total = len(f.get("functions", []))
                        documented = sum(1 for fn in f.get("functions", []) if fn.get("has_docstring"))
                        csv_data.append({
                            "File": file_name,
                            "Total Functions": total,
                            "Documented": documented,
                            "Missing": total - documented,
                            "Coverage": f"{(documented/total*100) if total > 0 else 0:.1f}%"
                        })
                    
                    df = pd.DataFrame(csv_data)
                    csv_string = df.to_csv(index=False)
                    
                    st.download_button(
                        "üíæ Download CSV",
                        data=csv_string,
                        file_name=f"code_review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )